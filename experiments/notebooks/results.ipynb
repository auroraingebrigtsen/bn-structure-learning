{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0060d9b4",
   "metadata": {},
   "source": [
    "# Notebook for analyzing the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e378a7b",
   "metadata": {},
   "source": [
    "In this notebook we analyze the results from the experiments we ran. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db37de6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from bnsl.scoring import compute_shd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c81e32",
   "metadata": {},
   "source": [
    "Store the records as a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea341fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path.cwd().parents[1]    # two levels up\n",
    "files = list((root / \"data\" / \"results\").rglob(\"*.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3abeacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "records = []\n",
    "for f in files:\n",
    "    with open(f) as fp:\n",
    "        r = json.load(fp)\n",
    "        record = {\n",
    "            \"algorithm\": r[\"algorithm\"],\n",
    "            \"network\": r[\"network\"].split(\"/\")[-1].split(\".\")[0],\n",
    "            \"num_samples\": r[\"num_samples\"],\n",
    "            \"score\": r[\"score\"],\n",
    "            \"optimal_upper_bound\": r[\"params\"].get(\"optimal_upper_bound\"),\n",
    "            \"runtime\": r[\"seconds_elapsed\"],\n",
    "            \"k\": r[\"params\"].get(\"k\"),\n",
    "            \"l\": r[\"params\"].get(\"l\"),\n",
    "            \"num_vars\": r[\"num_variables\"],\n",
    "            \"seed\": r[\"seed\"],\n",
    "            \"parent_map\": r.get(\"parent_map\"),\n",
    "        }\n",
    "        records.append(record)\n",
    "\n",
    "df = pd.DataFrame(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ede9ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac4033a",
   "metadata": {},
   "source": [
    " Create a table with only approximation algorithm, and true fields from dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1ef8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "approx_df = df[df[\"algorithm\"] == \"approximation_algorithm\"].drop(columns=[\"algorithm\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8686fe17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the true score from silander myllymaki to the corresponding approximation results\n",
    "approx_df[\"dp_score\"] = approx_df.apply(\n",
    "    lambda row: df[\n",
    "        (df[\"algorithm\"] == \"silander_myllymaki\") &\n",
    "        (df[\"network\"] == row[\"network\"]) &\n",
    "        (df[\"num_samples\"] == row[\"num_samples\"]) &\n",
    "        (df[\"seed\"] == row[\"seed\"])\n",
    "    ][\"score\"].values[0], axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b917ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the true pm from silander myllymaki to the corresponding approximation results\n",
    "approx_df[\"dp_parent_map\"] = approx_df.apply(\n",
    "    lambda row: df[\n",
    "        (df[\"algorithm\"] == \"silander_myllymaki\") &\n",
    "        (df[\"network\"] == row[\"network\"]) &\n",
    "        (df[\"num_samples\"] == row[\"num_samples\"]) &\n",
    "        (df[\"seed\"] == row[\"seed\"])\n",
    "    ][\"parent_map\"].values[0], axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02957dff",
   "metadata": {},
   "source": [
    "Compute SHD from the DP network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f508267f",
   "metadata": {},
   "outputs": [],
   "source": [
    "approx_df[\"SHD\"] = approx_df.apply(\n",
    "    lambda row: compute_shd(\n",
    "        root / \"networks\" /  \"small\" / f\"{row['network']}.bif\",\n",
    "       row[\"parent_map\"],\n",
    "    ), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f158a7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "approx_df.sort_values([\"network\", \"num_samples\"]).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e312e56",
   "metadata": {},
   "source": [
    "Make k and l ints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a22b8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "approx_df[\"k\"] = approx_df[\"k\"].astype(int)\n",
    "approx_df[\"l\"] = approx_df[\"l\"].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113efbea",
   "metadata": {},
   "source": [
    "Create one df for each network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffb365e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make one df per network\n",
    "network_dfs = {}\n",
    "for network in approx_df[\"network\"].unique():\n",
    "    network_dfs[network] = approx_df[approx_df[\"network\"] == network].drop(columns=[\"network\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8d2286",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_dfs[\"asia\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c1eadf",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3556b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_order = [\n",
    "    \"num_samples\",\n",
    "    \"seed\",\n",
    "    \"l\",\n",
    "    \"k\",\n",
    "    \"runtime\",\n",
    "    \"score\",\n",
    "    \"dp_score\",\n",
    "    \"optimal_upper_bound\",\n",
    "    \"SHD\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d249fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort globally before grouping\n",
    "approx_df = approx_df.sort_values([\"seed\", \"num_samples\", \"k\"])\n",
    "\n",
    "for net, df_net in approx_df.groupby(\"network\"):\n",
    "    print(f\"% --- {net} ---\")\n",
    "\n",
    "    df_print = df_net.drop(columns=[\"network\", \"parent_map\", \"dp_parent_map\", \"num_vars\"])\n",
    "\n",
    "    df_print = df_print[column_order]\n",
    "\n",
    "    # dynamically create column format string\n",
    "    colfmt = \"r\" * len(df_print.columns)\n",
    "\n",
    "    # generate the tabular\n",
    "    tabular = df_print.to_latex(\n",
    "        index=False,\n",
    "        float_format=\"%.3f\",\n",
    "        column_format=colfmt,\n",
    "        escape=False,\n",
    "    )\n",
    "\n",
    "    # wrap in table + resizebox\n",
    "    print(\n",
    "f\"\"\"\\\\begin{{table}}[H]\n",
    "\\\\centering\n",
    "\\\\scriptsize\n",
    "\\\\caption{{Approximation algorithm vs DP on the {net} network.}}\n",
    "\\\\label{{tab:approx_vs_dp_{net}}}\n",
    "\\\\resizebox{{\\\\textwidth}}{{!}}{{%\n",
    "{tabular}\n",
    "}}\n",
    "\\\\end{{table}}\n",
    "\n",
    "\"\"\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117e2e46",
   "metadata": {},
   "source": [
    "Generate network visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f572091d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pgmpy.models import DiscreteBayesianNetwork\n",
    "\n",
    "def draw_bn(pm, filename=\"bn.png\"):\n",
    "    # Convert pm into edge list\n",
    "    edges = [(parent, child) for child, parents in pm.items() for parent in parents]\n",
    "    bn = DiscreteBayesianNetwork(edges)\n",
    "\n",
    "    # Convert model into pygraphviz object\n",
    "    model_graphviz = bn.to_graphviz()\n",
    "\n",
    "    # Plot the model.\n",
    "    model_graphviz.draw(f\"plots/{filename}\", prog=\"dot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e708788b",
   "metadata": {},
   "outputs": [],
   "source": [
    "asia = network_dfs[\"asia\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878c031a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row_idx, row in asia.iterrows():\n",
    "    k = row[\"k\"]\n",
    "    l = row[\"l\"]\n",
    "    seed = row[\"seed\"]\n",
    "    num_samples = row[\"num_samples\"]\n",
    "    filename = f\"asia_k{k}_l{l}_seed{seed}_samples{num_samples}.png\"\n",
    "    draw_bn(row[\"parent_map\"], filename=filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f574fc09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bn-structure-learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
