{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb2b57d3",
   "metadata": {},
   "source": [
    "# Notebook for analyzing the results obtained from larger networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d646db08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from bnsl.metrics import compute_shd\n",
    "from typing import List, Tuple\n",
    "from math import log10, floor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3386ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path.cwd().parents[1]    # two levels up\n",
    "files = list((root / \"data\" / \"results\" / \"medium\").rglob(\"*.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c25b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "records = []\n",
    "for f in files:\n",
    "    with open(f) as fp:\n",
    "        r = json.load(fp)\n",
    "        record = {\n",
    "            \"algorithm\": r[\"algorithm\"],\n",
    "            \"network\": r[\"network\"].split(\"/\")[-1].split(\".\")[0],\n",
    "            \"num_samples\": r[\"num_samples\"],\n",
    "            \"score\": r[\"score\"],\n",
    "            \"theoretical_upper_bound\": r[\"bounds\"].get(\"theoretical_upper_bound\"),\n",
    "            \"naive_upper_bound\": r[\"bounds\"].get(\"naive_upper_bound\"),\n",
    "            \"runtime\": r[\"seconds_elapsed\"],\n",
    "            \"k\": r[\"params\"].get(\"k\"),\n",
    "            \"l\": r[\"params\"].get(\"l\"),\n",
    "            \"num_vars\": r[\"num_variables\"],\n",
    "            \"seed\": r[\"seed\"],\n",
    "            \"parent_map\": r.get(\"parent_map\"),\n",
    "        }\n",
    "        records.append(record)\n",
    "\n",
    "df = pd.DataFrame(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9ccaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e516c9e",
   "metadata": {},
   "source": [
    "##### Look at the number of ideals generated for each partial order "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5942199d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_size_of_ideals(n:int, l: int, k: int) -> int:\n",
    "    \"\"\" Returns the expected number of ideals for a partial order, given l and k values.\n",
    "     Based on lemma 19 from Partial Order Approach paper: |I(B)| = 1−ℓ+2**|B1|+2**|B2|+···+2**|Bℓ|\"\"\"\n",
    "    \n",
    "    q, r = divmod(n, k) #partition n into k equally sized sets:  r sets of size q+1, (k-r) sets  of size q\n",
    "\n",
    "    if l <= r:\n",
    "        size_big = l * (q + 1)\n",
    "\n",
    "        num_small_q_plus_1 = r - l \n",
    "        num_small_q = k - r  \n",
    "        L = num_small_q_plus_1 + num_small_q + 1\n",
    "\n",
    "        return (1- L+ num_small_q_plus_1 * (2 ** (q + 1)) + num_small_q * (2 ** q) + (2 ** size_big))\n",
    "    else: # l > r\n",
    "        size_big = r * (q + 1) + (l - r) * q\n",
    "\n",
    "        num_small_q = k - l \n",
    "        L = num_small_q + 1\n",
    "\n",
    "        return (1- L+ num_small_q * (2 ** q) + (2 ** size_big))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac7e385",
   "metadata": {},
   "outputs": [],
   "source": [
    "networks_sorted = [\n",
    "    (\"CHILD\", 20),\n",
    "    (\"INSURANCE\", 27),\n",
    "    (\"WATER\", 32),\n",
    "    (\"MILDEW\", 35),\n",
    "    (\"ALARM\", 37),\n",
    "    (\"HAILFINDER\", 56),\n",
    "    (\"CARPO\", 60),\n",
    "]\n",
    "\n",
    "k_l_grid: List[Tuple[int, int]] = [\n",
    "    (2, 1),\n",
    "    (3, 2),\n",
    "    (4, 3),\n",
    "    (5, 4),\n",
    "]\n",
    "\n",
    "def to_sci_latex(x: int) -> str:\n",
    "    \"\"\"\n",
    "    Format integer x  in latex \n",
    "    \"\"\"\n",
    "    if x == 0:\n",
    "        return \"$0$\"\n",
    "    exp = floor(log10(x))\n",
    "    mant = x / (10 ** exp)\n",
    "    # 2 decimal digits \n",
    "    return f\"${mant:.2f} \\\\times 10^{{{exp}}}$\"\n",
    "\n",
    "# Print LaTeX table\n",
    "print(r\"\\begin{table}[H]\")\n",
    "print(r\"\\centering\")\n",
    "print(r\"\\begin{tabular}{l r \" + \"r\" * len(k_l_grid) + \"}\")\n",
    "print(r\"\\toprule\")\n",
    "\n",
    "# Header row\n",
    "header = [r\"\\textbf{Network}\", r\"\\textbf{Nodes $n$}\"]\n",
    "for k, l in k_l_grid:\n",
    "    header.append(fr\"$\\mathbf{{(k={k},\\,\\ell={l})}}$\")\n",
    "print(\" & \".join(header) + r\" \\\\\")\n",
    "print(r\"\\midrule\")\n",
    "\n",
    "# Data rows\n",
    "for name, n in networks_sorted:\n",
    "    row = [name, str(n)]\n",
    "    for k, l in k_l_grid:\n",
    "        ideals_size = get_size_of_ideals(n, l, k)\n",
    "        row.append(to_sci_latex(ideals_size))\n",
    "    print(\" & \".join(row) + r\" \\\\\")\n",
    "print(r\"\\bottomrule\")\n",
    "print(r\"\\end{tabular}\")\n",
    "print(r\"\\caption{Number of ideals generated by the first partial order \"\n",
    "      r\"for different $(k,\\ell)$ values.}\")\n",
    "print(r\"\\end{table}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000d726f",
   "metadata": {},
   "source": [
    "##### Plot analytical score against empirical runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915a4c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avg = (\n",
    "    df.groupby([\"network\", \"num_samples\", \"k\", \"l\", \"num_vars\"])\n",
    "      .agg(runtime=(\"runtime\", \"mean\"))\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "df_avg[\"theory_log\"] = (df_avg[\"l\"] / df_avg[\"k\"]) * df_avg[\"num_vars\"] # log_2(2**(l/k * n)) = (l/k)*n\n",
    "df_avg[\"actual_log\"] = np.log2(df_avg[\"runtime\"])\n",
    "\n",
    "networks = df_avg[\"network\"].unique()\n",
    "\n",
    "for net in networks:\n",
    "    subset = df_avg[df_avg[\"network\"] == net]\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "\n",
    "    # one scatter series per (k, l)\n",
    "    for (k, l), sub2 in subset.groupby([\"k\", \"l\"]):\n",
    "        plt.scatter(\n",
    "            sub2[\"theory_log\"],\n",
    "            sub2[\"actual_log\"],\n",
    "            label=f\"k={k}, ℓ={l}\",\n",
    "            alpha=0.8,\n",
    "        )\n",
    "\n",
    "    plt.title(f\"Runtime scaling for {net}-network\")\n",
    "    plt.xlabel(r\"$\\log(\\text{theoretical runtime})$\")\n",
    "    plt.ylabel(r\"$\\log(\\text{empirical runtime})$\")\n",
    "    plt.legend(title=\"(k, ℓ)\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    outfile = root / f\"experiments/plots/runtime_scaling_{net}.png\"\n",
    "    plt.savefig(outfile, dpi=300) \n",
    "    print(f\"Saved {outfile}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3896ac4a",
   "metadata": {},
   "source": [
    "##### Score vs runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fa97f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg = (\n",
    "    df.groupby([\"num_samples\", \"network\", \"k\", \"l\"], as_index=False)\n",
    "      .agg(\n",
    "          score=(\"score\", \"mean\"),\n",
    "          naive_upper_bound=(\"naive_upper_bound\", \"mean\"),\n",
    "      )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e991236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to a single sample size\n",
    "TARGET_N = 100\n",
    "df_1000 = df_agg[df_agg[\"num_samples\"] == TARGET_N].copy()\n",
    "\n",
    "# Add approximation ratio\n",
    "df_1000[\"ratio\"] = df_1000[\"l\"] / df_1000[\"k\"]\n",
    "\n",
    "# Plot one figure per network\n",
    "for net, sub in df_1000.groupby(\"network\"):\n",
    "    plt.figure(figsize=(6, 4))\n",
    "\n",
    "    # Sort by ratio so the line is monotone\n",
    "    sub = sub.sort_values(\"ratio\")\n",
    "\n",
    "    x = sub[\"ratio\"].to_numpy()\n",
    "    y = sub[\"score\"].to_numpy()\n",
    "\n",
    "    # Approximation score curve\n",
    "    plt.plot(\n",
    "        x,\n",
    "        y,\n",
    "        marker=\"o\",\n",
    "        linestyle=\"-\",\n",
    "        label=f\"Approx score (n={TARGET_N})\"\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    kl_list = [tuple(x) for x in sub[[\"k\", \"l\"]].drop_duplicates().to_numpy()]\n",
    "    kl_list = sorted(kl_list)\n",
    "\n",
    "    xticks = [l / k for (k, l) in kl_list]\n",
    "    xticklabels = [fr\"$\\frac{{{int(l)}}}{{{int(k)}}}$\" for (k, l) in kl_list]\n",
    "\n",
    "    plt.xticks(xticks, xticklabels)\n",
    "\n",
    "    plt.xlabel(r\"Approximation ratio $\\frac{l}{k}$\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.title(f\"Score vs. approximation ratio ({net}, n={TARGET_N})\")\n",
    "    plt.legend(fontsize=7)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    outfile = root / f\"experiments/plots/plot_score_vs_ratio_{net}_n{TARGET_N}.png\"\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34bdf9f",
   "metadata": {},
   "source": [
    "##### Time vs ratio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27a819a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avg = (\n",
    "    df.groupby([\"network\", \"num_samples\", \"k\", \"l\", \"num_vars\"])\n",
    "      .agg(runtime=(\"runtime\", \"mean\"))\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "df_avg[\"ratio\"] = df_avg[\"l\"] / df_avg[\"k\"]\n",
    "\n",
    "# Compute base c such that runtime ≈ c^n\n",
    "df_avg[\"exp_base\"] = df_avg[\"runtime\"] ** (1 / df_avg[\"num_vars\"])\n",
    "\n",
    "networks = df_avg[\"network\"].unique()\n",
    "\n",
    "for net in networks:\n",
    "    subset_net = df_avg[df_avg[\"network\"] == net]\n",
    "    sample_sizes = subset_net[\"num_samples\"].unique()\n",
    "\n",
    "    plt.figure(figsize=(7, 5))\n",
    "\n",
    "    for S in sorted(sample_sizes):\n",
    "        sub = subset_net[subset_net[\"num_samples\"] == S].sort_values(\"ratio\")\n",
    "\n",
    "        plt.plot(\n",
    "            sub[\"ratio\"],\n",
    "            sub[\"exp_base\"],\n",
    "            marker=\"o\",\n",
    "            label=f\"N={S}\"\n",
    "        )\n",
    "\n",
    "    plt.xlabel(r\"Approximation ratio $\\ell/k$\")\n",
    "    plt.ylabel(r\"Base of exponential runtime\")\n",
    "\n",
    "    plt.title(f\"Empirical exponential base vs approximation ratio ({net})\")\n",
    "    plt.legend(title=\"Sample size\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    outfile = root / f\"experiments/plots/exp_base_vs_ratio_{net}.png\"\n",
    "    plt.savefig(outfile, dpi=300)\n",
    "    print(f\"Saved {outfile}\")\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a35b86",
   "metadata": {},
   "source": [
    "##### Score vs runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7e2d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "S = 1000\n",
    "\n",
    "df_fixed = df[df[\"num_samples\"] == S]\n",
    "\n",
    "df_avg = (\n",
    "    df_fixed.groupby([\"network\", \"k\", \"l\"])\n",
    "            .agg(runtime=(\"runtime\", \"mean\"),\n",
    "                 score=(\"score\", \"mean\"))\n",
    "            .reset_index()\n",
    ")\n",
    "\n",
    "df_avg[\"log_runtime\"] = np.log(df_avg[\"runtime\"])\n",
    "\n",
    "networks = df_avg[\"network\"].unique()\n",
    "\n",
    "for net in networks:\n",
    "    subset = df_avg[df_avg[\"network\"] == net]\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "\n",
    "    for (k, l), sub2 in subset.groupby([\"k\", \"l\"]):\n",
    "        plt.scatter(\n",
    "            sub2[\"log_runtime\"],\n",
    "            sub2[\"score\"],\n",
    "            label=f\"k={k}, ℓ={l}\",\n",
    "            alpha=0.8,\n",
    "        )\n",
    "\n",
    "    plt.title(f\"Score vs. runtime for {net}-network (N={S})\")\n",
    "    plt.xlabel(r\"$\\log(\\text{runtime})$\")\n",
    "    plt.ylabel(\"Score (BIC)\")\n",
    "    plt.legend(title=\"(k, ℓ)\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    outfile = root / f\"experiments/plots/score_vs_runtime_{net}_N{S}.png\"\n",
    "    plt.savefig(outfile, dpi=300)\n",
    "    print(f\"Saved {outfile}\")\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6ff39a",
   "metadata": {},
   "source": [
    "##### Hailfinder!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6311754b",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = list((root / \"data\" / \"results\" / \"large\").rglob(\"*.json\"))\n",
    "records = []\n",
    "for f in files:\n",
    "    with open(f) as fp:\n",
    "        r = json.load(fp)\n",
    "        record = {\n",
    "            \"algorithm\": r[\"algorithm\"],\n",
    "            \"network\": r[\"network\"].split(\"/\")[-1].split(\".\")[0],\n",
    "            \"num_samples\": r[\"num_samples\"],\n",
    "            \"score\": r[\"score\"],\n",
    "            \"theoretical_upper_bound\": r[\"bounds\"].get(\"theoretical_upper_bound\"),\n",
    "            \"naive_upper_bound\": r[\"bounds\"].get(\"naive_upper_bound\"),\n",
    "            \"runtime\": r[\"seconds_elapsed\"],\n",
    "            \"k\": r[\"params\"].get(\"k\"),\n",
    "            \"l\": r[\"params\"].get(\"l\"),\n",
    "            \"num_vars\": r[\"num_variables\"],\n",
    "            \"seed\": r[\"seed\"],\n",
    "            \"parent_map\": r.get(\"parent_map\"),\n",
    "        }\n",
    "        records.append(record)\n",
    "\n",
    "df_large = pd.DataFrame(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ab2047",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_large.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e14942",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pgmpy.readwrite import BIFReader\n",
    "def index_pm_to_name_pm(pm_idx, network_path):\n",
    "    reader = BIFReader(str(network_path))\n",
    "    model = reader.get_model()\n",
    "    var_names = list(model.nodes())\n",
    "    index_to_name = {i: name for i, name in enumerate(var_names)}\n",
    "    \n",
    "    return {\n",
    "        index_to_name[int(child)]: {index_to_name[int(p)] for p in parents}\n",
    "        for child, parents in pm_idx.items()\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba05977",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_path = root / \"networks\" / \"large\" / \"hailfinder.bif\"\n",
    "\n",
    "pm_idx = df_large[\n",
    "    (df_large[\"network\"] == \"hailfinder\") &\n",
    "    (df_large[\"num_samples\"] == 10000)\n",
    "][\"parent_map\"].iloc[0]\n",
    "\n",
    "pm_named = index_pm_to_name_pm(pm_idx, network_path)\n",
    "\n",
    "compute_shd(network_path, pm_named)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bn-structure-learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
